<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Nazmul Karim</title>
  
  <meta name="author" content="Nazmul Karim">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
<link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <link rel   = "stylesheet" href    ="https://use.fontawesome.com/releases/v5.0.7/css/all.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Nazmul Karim</name>
              </p>
              <p>
		I am a Research Scientist at Bosch, working on the foundation model for sensor and wi-fi data interpretation. I recently completed my Ph.D. journey at the <a href="https://lcwnlab.eecs.ucf.edu/">LCWN Lab, UCF</a>, where I was advised by <a href="https://www.ece.ucf.edu/person/nazanin-rahnavard/">Prof. Nazanin Rahnavard</a> and co-advised by <a href="https://www.crcv.ucf.edu/person/mubarak-shah/">Prof. Mubarak Shah</a>. I have a broad interest in various topics in computer vision and machine learning. My Ph.D. research primarily focused on safe, responsible, and robust AI; including adversarial attacks and defenses, out-of-distribution (OOD) robustness, domain adaptation, and learning with noisy labels. I have also worked on compressive sensing, 3D Scene generation, video generation, continual learning, and multi-modal learning.	
<!-- 		   I am a Postdoctoral Scientist at Amazon Search Science & AI, working at the intersection of video understanding and large language models. I recently completed my Ph.D. journey at the <a href="https://www.crcv.ucf.edu/">Center for Research in Computer Vision, UCF</a>, where I was advised by <a href="https://www.crcv.ucf.edu/person/mubarak-shah/">Prof. Mubarak Shah</a>. I have a broad interest in various topics in computer vision and machine learning. My Ph.D. research primarily focused on learning with limited labels, including semi-supervised learning, few-shot learning, and self-supervised learning. I have also worked on activity detection, temporal action localization, learning with noisy labels, and multi-modal learning.    -->
<!-- 		      I am a Postdoctoral Scientist at Amazon Search Science & AI working at the intersection of video understanding and large language models. I recently wrapped up my Ph.D. journey at <a href="https://www.crcv.ucf.edu/">Center for Research in Computer Vision, UCF</a>, where I am advised by <a href="https://www.crcv.ucf.edu/person/mubarak-shah/">Prof. Mubarak Shah</a>. I am broadly interested interested in computer vision, and machine learning. My PhD research primarily focused on learning with limited labels, which mostly includes semi-supervised learning, few-shot learning, and self-supervised learning. I have also worked on activity detection, temporal action localization, learning with noisy labels, and multi-modal learning. -->
              </p>
              <p style="text-align:center">
                <a href="mailto:nazmul.karim170@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Resume_Nazmul_C.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=mgi3sEgAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/nazmul170">Twitter</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/nazmul-karim-1b5805115/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://github.com/nazmul-karim170">GitHub</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/rsz_photo_nazmul.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/rsz_photo_nazmul.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
	
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Updates</heading>
              <p>
		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> July 2024: My work on AI security got accepted to ACM CCS 2024<br>
		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> July 2024: My work on AI security got accepted to ECCV 2024<br>
		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> July 2024: <a href="https://latenteditor.github.io/">LatentEditor</a> got accepted to ECCV 2024<br>
		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> July 2024: <a href="https://free-editor.github.io/">Free-Editor</a> got accepted to ECCV 2024<br>
		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> February 2024: Joined Bosch as a Research Scientist<br>
		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> December 2023: Joined UCF CRCV as a Postdoctoral Scientist<br>
		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> November 2023: Successfully defended my PhD dissertation<br>
		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> May 2023: Started summer internship at Amazon Web Services<br>
		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> February 2023: My work on source free domain adaptation got accepted to CVPR 2023<br>
		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> May 2022: Started summer internship at SRI International<br>
		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> April 2022: Paper accepted to SPIE 2022<br>
		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> February 2022: Three papers accepted to CVPR 2022<br>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> October 2021: Paper accepted to IEEE Transaction on Forensics and Information Security (TIFS)<br>
		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> May 2020: Completed MS in Computer Engineering<br>
		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> June 2019: Paper accepted to IEEE MLSP 2019<br>
<!-- 		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> March 2021: Paper accepted to CVPR 2021<br>
		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> January 2021: Paper accepted to ICLR 2021<br> -->
<!--                 &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> May 2021: Started summer internship with the Perception team at Aurora<br>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> March 2021: Paper accepted at CVPR 2021<br>
		      &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> July 2022: Our realistic semi-supervised learning paper has been selected for <font color="red">Oral</font> presentation at ECCV 2022<br>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> January 2021: Paper accepted at ICLR 2021<br>
		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> January 2021: Our Gabriella paper has been awarded the <font color="red">best scientific paper</font> award at ICPR 2020<br>
		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> October 2020: Paper accepted at ICPR 2020<br>
	        &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> June 2020: Placed first at ActEV SDL Challenge (ActivityNet workshop at CVPR 2020)<br>
		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> October 2019: Placed second at the TRECVID leaderboard<br>
		&nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> August 2018: Started PhD at CRCV, UCF<br>  -->
              </p>
            </td>
          </tr>
        </tbody></table>
	      
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
             <tr>
             <td style="padding:20px;width:100%;vertical-align:middle"> 
               <heading>Publications</heading>
            </td>
        </tr> 
    </tbody></table>  

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		
	<tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/csfda_cvpr2023.png" alt="csfda-cvpr2023" width="160" style="border-style: none">
            </td>
            <td style="padding-bottom:35px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Karim_C-SFDA_A_Curriculum_Learning_Aided_Self-Training_Framework_for_Efficient_Source_CVPR_2023_paper.pdf" id="MCG_journal">
                <papertitle>C-SFDA: A Curriculum Learning Aided Self-Training Framework for Efficient Source Free Domain Adaptation</papertitle>
              </a>
              <br>
              <strong>Nazmul Karim</strong>, <a href="https://niluthpol.github.io/">Niluthpool Mithun Chowdhury</a>, <a href="https://www.linkedin.com/in/ye-yu">Abhinav Rajvanshi</a>, <a href="https://www.linkedin.com/in/matthew-hall-35525949">Han-pang Chiu</a>, <a href="">Supun Samarasekera</a>, <a href="">Nazanin Rahnavard</a>
              <br>
              <em>CVPR</em>, 2023
              <br>
              <a href=https://openaccess.thecvf.com/content/CVPR2023/papers/Karim_C-SFDA_A_Curriculum_Learning_Aided_Self-Training_Framework_for_Efficient_Source_CVPR_2023_paper.pdf">paper</a>/
	      <a href=https://github.com/nazmul-karim170/C-SFDA_Source-Free-Domain-Adaptation">code</a>/
              <a href="data/csfda_cvpr2023.bib">bibtex</a> /
              <a href="https://www.youtube.com/watch?v=tA-8U4rD32I">video</a>
              <p>
		   A curriculum learning-aided self-training framework for SFDA that adapts efficiently and reliably to changes across domains based on selective pseudo-labeling. Specifically, we employ a curriculum learning scheme to promote learning from a restricted amount of pseudo labels selected based on their reliabilities. This simple yet effective step successfully prevents label noise propagation during different stages of adaptation and eliminates the need for costly memory-bank based label refinement.
		</p>
            </td>
          </tr>
          <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/unicon_cvpr2022.png" alt="unicon-cvpr2021" width="160" style="border-style: none">
            </td>
            <td style="padding-bottom:35px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2203.14542" id="MCG_journal">
                <papertitle>UNICON: Combating Label Noise Through Uniform Selection and Contrastive Learning</papertitle>
              </a>
              <br>
              <strong>Nazmul Karim</strong>, <a href="https://www.linkedin.com/in/mamshad-nayeem-rizve/">Mamshad Nayeem Rizve</a>, <a href="https://www.ece.ucf.edu/person/nazanin-rahnavard/">Nazanin Rahnavard</a>, <a href="https://ajmalsaeed.net/">Ajmal Mian</a>, <a href="https://www.crcv.ucf.edu/person/mubarak-shah/">Mubarak Shah</a>
              <br>
              <em>CVPR</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2203.14542">arxiv</a> /
              <a href="data/unicon_cvpr2022.bib">bibtex</a> /
              <a href="https://github.com/nazmul-karim170/unicon-noisy-label">code</a>
              <p>
		UNICON is a robust sample selection approach for training with high label noise. It incorporates a Jensen-Shannon divergence-based uniform sample selection mechanism and contrastive learning.
	</p>
            </td>
          </tr>
          <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/cnll_cvpr2022.png" alt="cnll-cvpr2021" width="160" style="border-style: none">
            </td>
            <td style="padding-bottom:35px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/CVPR2022W/CLVision/papers/Karim_CNLL_A_Semi-Supervised_Approach_for_Continual_Noisy_Label_Learning_CVPRW_2022_paper.pdf" id="MCG_journal">
                <papertitle>CNLL: A Semi-supervised Approach For Continual Noisy Label Learning</papertitle>
              </a>
              <br>
              <strong>Nazmul Karim</strong>, <a href="https://www.linkedin.com/in/umarkhalidai/">Umar Khalid</a>, <a href="https://www.linkedin.com/in/ashkan-esmaeili-19391118a/">Ashkan Esmaeili</a>, <a href="https://www.ece.ucf.edu/person/nazanin-rahnavard/">Nazanin Rahnavard</a>
              <br>
              <em>CVPR</em>, 2022
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2022W/CLVision/papers/Karim_CNLL_A_Semi-Supervised_Approach_for_Continual_Noisy_Label_Learning_CVPRW_2022_paper.pdf">arxiv</a> /
              <a href="data/cnll_cvpr2022.bib">bibtex</a> /
              <a href="https://github.com/nazmul-karim170/CNLL-Continual_Learning_Noisy_Labels">code</a>
              <p>
		The task of continual learning requires careful design of algorithms that can tackle catastrophic forgetting. However, the noisy label, which is inevitable in a real-world
scenario, seems to exacerbate the situation. While very few
studies have addressed the issue of continual learning under
noisy labels, long training time and complicated training schemes limit their applications in most cases. In contrast, we propose a simple purification technique to effectively cleanse the online data stream that is both cost-effective and more accurate.
	</p>
            </td>
          </tr>	
          <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/rodd_cvpr2022.png" alt="rodd-cvpr2021" width="160" style="border-style: none">
            </td>
            <td style="padding-bottom:35px;width:75%;vertical-align:middle">
              <a href=https://arxiv.org/pdf/2204.02553" id="MCG_journal">
                <papertitle>RODD: A Self-Supervised Approach for Robust Out-of-Distribution Detection</papertitle>
              </a>
              <br>
              <a href="https://www.linkedin.com/in/umarkhalidai/">Umar Khalid</a>, <a href="https://www.linkedin.com/in/ashkan-esmaeili-19391118a/">Ashkan Esmaeili</a>, <strong>Nazmul Karim</strong>, <a href="https://www.ece.ucf.edu/person/nazanin-rahnavard/">Nazanin Rahnavard</a>
              <br>
              <em>CVPR</em>, 2022
              <br>
              <a href="https://arxiv.org/pdf/2204.02553">arxiv</a> /
              <a href="data/rodd_cvpr2022.bib">bibtex</a> /
              <a href="https://github.com/nazmul-karim170/RODD">code</a>
              <p>
		We propose a simple yet effective generalized OOD detection method independent of out-of-distribution datasets. Our approach relies on self-supervised feature learning of the training samples, where the embeddings lie on a compact low-dimensional space. Motivated by the recent studies that show self-supervised adversarial contrastive learning helps robustify the model, we empirically show that a pre-trained model with self-supervised contrastive learning yields a better model for uni-dimensional
		feature learning in the latent space.
	</p>
            </td>
          </tr>	
        

  </table>
</body>

</html>
